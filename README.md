<p align="center">
  <img src="https://img.shields.io/badge/Python-3.11+-blue?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/FastAPI-0.104+-00897B?style=for-the-badge&logo=fastapi&logoColor=white" alt="FastAPI"/>
  <img src="https://img.shields.io/badge/Whisper-OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white" alt="Whisper"/>
  <img src="https://img.shields.io/badge/License-MIT-green?style=for-the-badge" alt="License"/>
</p>

<h1 align="center">âš¡ Anything Skills</h1>

<p align="center">
  <strong>ä»è§†é¢‘å†…å®¹æå–çŸ¥è¯†ï¼Œè‡ªåŠ¨ç”Ÿæˆ Claude Skills</strong>
</p>

<p align="center">
  <em>Transform video content into structured Claude Skills with AI-powered extraction</em>
</p>

---

## âœ¨ Features

| Feature | Status | Description |
|---------|--------|-------------|
| ğŸ¬ **Video Extraction** | âœ… Ready | Bilibili & YouTube video processing via yt-dlp |
| ğŸ™ï¸ **AI Transcription** | âœ… Ready | OpenAI Whisper for video/audio transcription |
| ğŸ§  **Skills Generation** | âœ… Ready | LLM-powered knowledge extraction to SKILL.md |
| ğŸ” **Skills Marketplace** | âœ… Ready | Search & install from skills.sh |
| ğŸ“¦ **GitHub Search** | ğŸŸ¡ Partial | Repository search only (no content extraction) |
| ğŸ“„ **ArXiv Papers** | ğŸ”´ Planned | Paper parsing (coming soon) |
| ğŸŒ **Web Crawler** | ğŸ”´ Planned | General web content (coming soon) |

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Content Sources                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Bilibili âœ…     â”‚   YouTube âœ…     â”‚   GitHub/ArXiv ğŸ”´     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                  â”‚
         â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Video Pipeline (yt-dlp + Whisper)               â”‚
â”‚  â€¢ Download Video  â€¢ Extract Audio  â€¢ Transcribe to Text    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   UnifiedContent Model                       â”‚
â”‚  { title, author, full_text, sections[], metadata }          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LLM Experience Extractor                    â”‚
â”‚  â€¢ Knowledge Points  â€¢ Best Practices  â€¢ Troubleshooting     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Skills Generator                          â”‚
â”‚  Output: SKILL.md files â†’ output/skills/<name>/              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

```bash
# macOS
brew install ffmpeg

# Python 3.11+
pip install -r requirements.txt
```

### Installation

```bash
git clone git@github.com:Ontos-AI/anything-skills.git
cd anything-skills
pip install -r requirements.txt
cp .env.example .env  # Fill in your API keys
```

### Usage

#### 1. Start API Server

```bash
uvicorn src.api.main:app --reload
```

#### 2. Open Web UI

| UI | URL | Description |
|----|-----|-------------|
| API Docs | http://localhost:8000/docs | OpenAPI documentation |
| Anything2Skills | http://localhost:8000/anything2skills | Main web interface |
| Agent Arena | http://localhost:8000/agent-arena | Agent comparison tool |

#### 3. CLI Mode (Bilibili)

```bash
# Metadata only
python test_bilibili.py "https://www.bilibili.com/video/BV1xxxxx"

# Full extraction with transcription
python test_bilibili.py "https://www.bilibili.com/video/BV1xxxxx" --full

# Specify Whisper model (tiny/base/small/medium/large)
python test_bilibili.py "https://www.bilibili.com/video/BV1xxxxx" --full --model=small
```

---

## ğŸ“¡ API Reference

### Core Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `POST` | `/api/videos/extract` | Extract skills from video URL |
| `POST` | `/api/anything2skills/generate` | Generate skill from prompt |
| `POST` | `/api/anything2skills/install` | Install skill from skills.sh |
| `GET` | `/api/anything2skills/search` | Search local/marketplace/GitHub |

### Legacy Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| `GET` | `/api/v1/sources` | List supported sources |
| `POST` | `/api/v1/extract` | Extract content (Bilibili only) |
| `GET` | `/api/v1/content` | List extracted contents |

### Example: Extract from Video

```bash
curl -X POST http://localhost:8000/api/videos/extract \
  -H "Content-Type: application/json" \
  -d '{
    "video_url": "https://www.youtube.com/watch?v=xxxxx",
    "save": true
  }'
```

---

## ğŸ“ Project Structure

```
anything-skills/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ sources/              # Content source processors
â”‚   â”‚   â”œâ”€â”€ base.py           # SourceProcessor base class
â”‚   â”‚   â””â”€â”€ bilibili.py       # Bilibili processor
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ video_pipeline.py # yt-dlp + Whisper pipeline
â”‚   â”‚   â”œâ”€â”€ llm.py            # LLM skill generation
â”‚   â”‚   â”œâ”€â”€ skills_store.py   # Local SKILL.md storage
â”‚   â”‚   â”œâ”€â”€ skills_sh.py      # skills.sh marketplace
â”‚   â”‚   â””â”€â”€ github_search.py  # GitHub repo search
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ unified.py        # Data models
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI app
â”‚   â”‚   â”œâ”€â”€ routes.py         # Core API routes
â”‚   â”‚   â””â”€â”€ anything2skills.py # Web UI routes
â”‚   â””â”€â”€ templates/            # Jinja2 templates
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ content/              # Extracted content
â”‚   â””â”€â”€ skills/               # Generated SKILL.md files
â””â”€â”€ requirements.txt
```

---

## ğŸ¯ Roadmap

- [x] **Phase 1**: Video extraction (Bilibili & YouTube)
- [x] **Phase 2**: Whisper transcription
- [x] **Phase 3**: LLM-based skill generation
- [x] **Phase 4**: skills.sh marketplace integration
- [ ] **Phase 5**: GitHub repository analysis
- [ ] **Phase 6**: ArXiv paper parsing
- [ ] **Phase 7**: General web crawler

---

## ğŸ› ï¸ Tech Stack

| Component | Technology |
|-----------|------------|
| Backend | FastAPI, Pydantic |
| Video | yt-dlp, FFmpeg |
| Transcription | OpenAI Whisper |
| LLM | OpenAI API (GPT-4o-mini) |
| Templates | Jinja2 |
| HTTP Client | httpx |

---

## âš™ï¸ Environment Variables

```bash
# Required
OPENAI_API_KEY=sk-xxx        # For LLM generation
OPENAI_BASE_URL=             # Optional: custom API endpoint
OPENAI_MODEL=gpt-4o-mini     # Model to use

# Optional
GITHUB_TOKEN=                # For GitHub search (higher rate limit)
WHISPER_MODEL=base           # Whisper model size
YTDLP_COOKIES_PATH=          # Path to cookies.txt for yt-dlp
```

---

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<p align="center">
  <sub>Built with â¤ï¸ by <a href="https://github.com/Ontos-AI">Ontos AI</a></sub>
</p>
